{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gluon CIFAR-10 Trained in Local Mode\n",
    "_**ResNet model in Gluon trained locally in a notebook instance**_\n",
    "\n",
    "---\n",
    "\n",
    "---\n",
    "\n",
    "_This notebook was created and tested on an ml.p3.8xlarge notebook instance._\n",
    "\n",
    "## Setup\n",
    "\n",
    "Import libraries and set IAM role ARN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker.mxnet import MXNet\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install pre-requisites for local training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The user has root access.\n",
      "SageMaker instance route table setup is ok. We are good to go.\n",
      "SageMaker instance routing for Docker is ok. We are good to go!\n"
     ]
    }
   ],
   "source": [
    "!/bin/bash setup.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Data\n",
    "\n",
    "We use the helper scripts to download CIFAR-10 training data and sample images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading training data...\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "from cifar10_utils import download_training_data\n",
    "download_training_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the `sagemaker.Session.upload_data` function to upload our datasets to an S3 location. The return value `inputs` identifies the location -- we will use this later when we start the training job.\n",
    "\n",
    "Even though we are training within our notebook instance, we'll continue to use the S3 data location since it will allow us to easily transition to training in SageMaker's managed environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input spec (in this case, just an S3 path): s3://sagemaker-us-west-2-272949293984/data/DEMO-gluon-cifar10\n"
     ]
    }
   ],
   "source": [
    "inputs = sagemaker_session.upload_data(path='data', key_prefix='data/DEMO-gluon-cifar10')\n",
    "print('input spec (in this case, just an S3 path): {}'.format(inputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Script\n",
    "\n",
    "We need to provide a training script that can run on the SageMaker platform. When SageMaker calls your function, it will pass in arguments that describe the training environment. The `train` function will check for the validation accuracy at the end of every epoch and checkpoints the best model so far, along with the optimizer state, in the folder `/opt/ml/checkpoints` if that folder path exists, else it will skip the checkpointing. Check the script below to see how this works.\n",
    "\n",
    "The network itself is a pre-built version contained in the [Gluon Model Zoo](https://mxnet.incubator.apache.org/versions/master/api/python/gluon/model_zoo.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from __future__ import print_function\r\n",
      "\r\n",
      "import json\r\n",
      "import logging\r\n",
      "import os\r\n",
      "import time\r\n",
      "\r\n",
      "import mxnet as mx\r\n",
      "from mxnet import autograd as ag\r\n",
      "from mxnet import gluon\r\n",
      "from mxnet.gluon.model_zoo import vision as models\r\n",
      "\r\n",
      "\r\n",
      "# ------------------------------------------------------------ #\r\n",
      "# Training methods                                             #\r\n",
      "# ------------------------------------------------------------ #\r\n",
      "\r\n",
      "def train(current_host, hosts, num_cpus, num_gpus, channel_input_dirs, model_dir, hyperparameters, **kwargs):\r\n",
      "    # retrieve the hyperparameters we set in notebook (with some defaults)\r\n",
      "    batch_size = hyperparameters.get('batch_size', 128)\r\n",
      "    epochs = hyperparameters.get('epochs', 100)\r\n",
      "    learning_rate = hyperparameters.get('learning_rate', 0.1)\r\n",
      "    momentum = hyperparameters.get('momentum', 0.9)\r\n",
      "    log_interval = hyperparameters.get('log_interval', 1)\r\n",
      "    wd = hyperparameters.get('wd', 0.0001)\r\n",
      "\r\n",
      "    if len(hosts) == 1:\r\n",
      "        kvstore = 'device' if num_gpus > 0 else 'local'\r\n",
      "    else:\r\n",
      "        kvstore = 'dist_device_sync'\r\n",
      "\r\n",
      "    ctx = [mx.gpu(i) for i in range(num_gpus)] if num_gpus > 0 else [mx.cpu()]\r\n",
      "    net = models.get_model('resnet34_v2', ctx=ctx, pretrained=False, classes=10)\r\n",
      "    batch_size *= max(1, len(ctx))\r\n",
      "\r\n",
      "    # load training and validation data\r\n",
      "    # we use the gluon.data.vision.CIFAR10 class because of its built in pre-processing logic,\r\n",
      "    # but point it at the location where SageMaker placed the data files, so it doesn't download them again.\r\n",
      "\r\n",
      "    part_index = 0\r\n",
      "    for i, host in enumerate(hosts):\r\n",
      "        if host == current_host:\r\n",
      "            part_index = i\r\n",
      "            break\r\n",
      "\r\n",
      "\r\n",
      "    data_dir = channel_input_dirs['training']\r\n",
      "    CHECKPOINTS_DIR = '/opt/ml/checkpoints'\r\n",
      "    checkpoints_enabled = os.path.exists(CHECKPOINTS_DIR)\r\n",
      "\r\n",
      "    train_data = get_train_data(num_cpus, data_dir, batch_size, (3, 32, 32),\r\n",
      "                                num_parts=len(hosts), part_index=part_index)\r\n",
      "    test_data = get_test_data(num_cpus, data_dir, batch_size, (3, 32, 32))\r\n",
      "\r\n",
      "    # Collect all parameters from net and its children, then initialize them.\r\n",
      "    net.initialize(mx.init.Xavier(magnitude=2), ctx=ctx)\r\n",
      "    # Trainer is for updating parameters with gradient.\r\n",
      "    trainer = gluon.Trainer(net.collect_params(), 'sgd',\r\n",
      "                            optimizer_params={'learning_rate': learning_rate, 'momentum': momentum, 'wd': wd},\r\n",
      "                            kvstore=kvstore)\r\n",
      "    metric = mx.metric.Accuracy()\r\n",
      "    loss = gluon.loss.SoftmaxCrossEntropyLoss()\r\n",
      "    net.hybridize()\r\n",
      "\r\n",
      "    best_accuracy = 0.0\r\n",
      "    for epoch in range(epochs):\r\n",
      "        # reset data iterator and metric at begining of epoch.\r\n",
      "        train_data.reset()\r\n",
      "        tic = time.time()\r\n",
      "        metric.reset()\r\n",
      "        btic = time.time()\r\n",
      "\r\n",
      "        for i, batch in enumerate(train_data):\r\n",
      "            data = gluon.utils.split_and_load(batch.data[0], ctx_list=ctx, batch_axis=0)\r\n",
      "            label = gluon.utils.split_and_load(batch.label[0], ctx_list=ctx, batch_axis=0)\r\n",
      "            outputs = []\r\n",
      "            Ls = []\r\n",
      "            with ag.record():\r\n",
      "                for x, y in zip(data, label):\r\n",
      "                    z = net(x)\r\n",
      "                    L = loss(z, y)\r\n",
      "                    # store the loss and do backward after we have done forward\r\n",
      "                    # on all GPUs for better speed on multiple GPUs.\r\n",
      "                    Ls.append(L)\r\n",
      "                    outputs.append(z)\r\n",
      "                for L in Ls:\r\n",
      "                    L.backward()\r\n",
      "            trainer.step(batch.data[0].shape[0])\r\n",
      "            metric.update(label, outputs)\r\n",
      "            if i % log_interval == 0 and i > 0:\r\n",
      "                name, acc = metric.get()\r\n",
      "                logging.info('Epoch [%d] Batch [%d]\\tSpeed: %f samples/sec\\t%s=%f' %\r\n",
      "                             (epoch, i, batch_size / (time.time() - btic), name, acc))\r\n",
      "            btic = time.time()\r\n",
      "\r\n",
      "        name, acc = metric.get()\r\n",
      "        logging.info('[Epoch %d] training: %s=%f' % (epoch, name, acc))\r\n",
      "        logging.info('[Epoch %d] time cost: %f' % (epoch, time.time() - tic))\r\n",
      "\r\n",
      "        name, val_acc = test(ctx, net, test_data)\r\n",
      "        logging.info('[Epoch %d] validation: %s=%f' % (epoch, name, val_acc))\r\n",
      "\r\n",
      "        # only save params on primary host\r\n",
      "        if checkpoints_enabled and current_host == hosts[0]:\r\n",
      "            if val_acc > best_accuracy:\r\n",
      "                best_accuracy = val_acc\r\n",
      "                logging.info('Saving the model, params and optimizer state')\r\n",
      "                net.export(CHECKPOINTS_DIR + \"/%.4f-cifar10\"%(best_accuracy), epoch)\r\n",
      "                trainer.save_states(CHECKPOINTS_DIR + '/%.4f-cifar10-%d.states'%(best_accuracy, epoch))\r\n",
      "\r\n",
      "    return net\r\n",
      "\r\n",
      "\r\n",
      "def save(net, model_dir):\r\n",
      "    # model_dir will be empty except on primary container\r\n",
      "    files = os.listdir(model_dir)\r\n",
      "    if files:\r\n",
      "        best = sorted(os.listdir(model_dir))[-1]\r\n",
      "        os.rename(os.path.join(model_dir, best), os.path.join(model_dir, 'model.params'))\r\n",
      "\r\n",
      "\r\n",
      "def get_data(path, augment, num_cpus, batch_size, data_shape, resize=-1, num_parts=1, part_index=0):\r\n",
      "    return mx.io.ImageRecordIter(\r\n",
      "        path_imgrec=path,\r\n",
      "        resize=resize,\r\n",
      "        data_shape=data_shape,\r\n",
      "        batch_size=batch_size,\r\n",
      "        rand_crop=augment,\r\n",
      "        rand_mirror=augment,\r\n",
      "        preprocess_threads=num_cpus,\r\n",
      "        num_parts=num_parts,\r\n",
      "        part_index=part_index)\r\n",
      "\r\n",
      "\r\n",
      "def get_test_data(num_cpus, data_dir, batch_size, data_shape, resize=-1):\r\n",
      "    return get_data(os.path.join(data_dir, \"test.rec\"), False, num_cpus, batch_size, data_shape, resize, 1, 0)\r\n",
      "\r\n",
      "\r\n",
      "def get_train_data(num_cpus, data_dir, batch_size, data_shape, resize=-1, num_parts=1, part_index=0):\r\n",
      "    return get_data(os.path.join(data_dir, \"train.rec\"), True, num_cpus, batch_size, data_shape, resize, num_parts,\r\n",
      "                    part_index)\r\n",
      "\r\n",
      "\r\n",
      "def test(ctx, net, test_data):\r\n",
      "    test_data.reset()\r\n",
      "    metric = mx.metric.Accuracy()\r\n",
      "\r\n",
      "    for i, batch in enumerate(test_data):\r\n",
      "        data = gluon.utils.split_and_load(batch.data[0], ctx_list=ctx, batch_axis=0)\r\n",
      "        label = gluon.utils.split_and_load(batch.label[0], ctx_list=ctx, batch_axis=0)\r\n",
      "        outputs = []\r\n",
      "        for x in data:\r\n",
      "            outputs.append(net(x))\r\n",
      "        metric.update(label, outputs)\r\n",
      "    return metric.get()\r\n",
      "\r\n",
      "\r\n",
      "# ------------------------------------------------------------ #\r\n",
      "# Hosting methods                                              #\r\n",
      "# ------------------------------------------------------------ #\r\n",
      "\r\n",
      "def model_fn(model_dir):\r\n",
      "    \"\"\"\r\n",
      "    Load the gluon model. Called once when hosting service starts.\r\n",
      "\r\n",
      "    :param: model_dir The directory where model files are stored.\r\n",
      "    :return: a model (in this case a Gluon network)\r\n",
      "    \"\"\"\r\n",
      "\r\n",
      "    net = models.get_model('resnet34_v2', ctx=mx.cpu(), pretrained=False, classes=10)\r\n",
      "    net.load_params('%s/model.params' % model_dir, ctx=mx.cpu())\r\n",
      "    return net\r\n",
      "\r\n",
      "\r\n",
      "def transform_fn(net, data, input_content_type, output_content_type):\r\n",
      "    \"\"\"\r\n",
      "    Transform a request using the Gluon model. Called once per request.\r\n",
      "\r\n",
      "    :param net: The Gluon model.\r\n",
      "    :param data: The request payload.\r\n",
      "    :param input_content_type: The request content type.\r\n",
      "    :param output_content_type: The (desired) response content type.\r\n",
      "    :return: response payload and content type.\r\n",
      "    \"\"\"\r\n",
      "    # we can use content types to vary input/output handling, but\r\n",
      "    # here we just assume json for both\r\n",
      "    parsed = json.loads(data)\r\n",
      "    nda = mx.nd.array(parsed)\r\n",
      "    output = net(nda)\r\n",
      "    prediction = mx.nd.argmax(output, axis=1)\r\n",
      "    response_body = json.dumps(prediction.asnumpy().tolist()[0])\r\n",
      "    return response_body, output_content_type\r\n"
     ]
    }
   ],
   "source": [
    "!cat 'cifar10.py'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Train (Local Mode)\n",
    "\n",
    "The ```MXNet``` estimator will create our training job. To switch from training in SageMaker's managed environment to training within a notebook instance, just set `train_instance_type` to `local_gpu`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = MXNet('cifar10.py',\n",
    "          py_version='py3',\n",
    "          role=role, \n",
    "          train_instance_count=1,\n",
    "          train_instance_type='local_gpu',\n",
    "          framework_version='1.1.0',\n",
    "          hyperparameters={'batch_size': 1024,\n",
    "                           'epochs': 50,\n",
    "                           'learning_rate': 0.1,\n",
    "                           'momentum': 0.9})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we've constructed our `MXNet` object, we can fit it using the data we uploaded to S3. SageMaker makes sure our data is available in the local filesystem, so our training script can simply read the data from disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating tmphruntu_algo-1-i0df6_1 ... \n",
      "\u001b[1Bting tmphruntu_algo-1-i0df6_1 ... \u001b[31merror\u001b[0m\n",
      "ERROR: for tmphruntu_algo-1-i0df6_1  Cannot start service algo-1-i0df6: OCI runtime create failed: container_linux.go:348: starting container process caused \"process_linux.go:402: container init caused \\\"process_linux.go:385: running prestart hook 1 caused \\\\\\\"error running hook: exit status 1, stdout: , stderr: exec command: [/usr/bin/nvidia-container-cli --load-kmods configure --ldconfig=@/sbin/ldconfig --device=all --compute --utility --require=cuda>=9.0 --pid=10148 /var/lib/docker/overlay2/e05b3ace24682a5facb97af35f65eef28074df608cdb3bf648c4c6e45e86e45d/merged]\\\\\\\\nnvidia-container-cli: initialization error: cuda error: no cuda-capable device is detected\\\\\\\\n\\\\\\\"\\\"\": unknown\n",
      "\n",
      "ERROR: for algo-1-i0df6  Cannot start service algo-1-i0df6: OCI runtime create failed: container_linux.go:348: starting container process caused \"process_linux.go:402: container init caused \\\"process_linux.go:385: running prestart hook 1 caused \\\\\\\"error running hook: exit status 1, stdout: , stderr: exec command: [/usr/bin/nvidia-container-cli --load-kmods configure --ldconfig=@/sbin/ldconfig --device=all --compute --utility --require=cuda>=9.0 --pid=10148 /var/lib/docker/overlay2/e05b3ace24682a5facb97af35f65eef28074df608cdb3bf648c4c6e45e86e45d/merged]\\\\\\\\nnvidia-container-cli: initialization error: cuda error: no cuda-capable device is detected\\\\\\\\n\\\\\\\"\\\"\": unknown\n",
      "Encountered errors while bringing up the project.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Failed to run: ['docker-compose', '-f', '/tmp/tmphrunTU/docker-compose.yaml', 'up', '--build', '--abort-on-container-exit'], Process exited with code: 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-b1d0de43edea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/ec2-user/anaconda3/envs/mxnet_p27/lib/python2.7/site-packages/sagemaker/estimator.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, inputs, wait, logs, job_name)\u001b[0m\n\u001b[1;32m    327\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_for_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 329\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_training_job\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_TrainingJob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    330\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_training_job\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ec2-user/anaconda3/envs/mxnet_p27/lib/python2.7/site-packages/sagemaker/estimator.pyc\u001b[0m in \u001b[0;36mstart_new\u001b[0;34m(cls, estimator, inputs)\u001b[0m\n\u001b[1;32m    842\u001b[0m         \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_spot_checkpoint_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocal_mode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 844\u001b[0;31m         \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mtrain_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    845\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    846\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_current_job_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ec2-user/anaconda3/envs/mxnet_p27/lib/python2.7/site-packages/sagemaker/session.pyc\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_mode, input_config, role, job_name, output_config, resource_config, vpc_config, hyperparameters, stop_condition, tags, metric_definitions, enable_network_isolation, image, algorithm_arn, encrypt_inter_container_traffic, train_use_spot_instances, checkpoint_s3_uri, checkpoint_local_path)\u001b[0m\n\u001b[1;32m    390\u001b[0m         \u001b[0mLOGGER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Creating training-job with name: %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m         \u001b[0mLOGGER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train request: %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_request\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 392\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_training_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mtrain_request\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m     def compile_model(\n",
      "\u001b[0;32m/home/ec2-user/anaconda3/envs/mxnet_p27/lib/python2.7/site-packages/sagemaker/local/local_session.pyc\u001b[0m in \u001b[0;36mcreate_training_job\u001b[0;34m(self, TrainingJobName, AlgorithmSpecification, OutputDataConfig, ResourceConfig, InputDataConfig, **kwargs)\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0mtraining_job\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_LocalTrainingJob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontainer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0mhyperparameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"HyperParameters\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m\"HyperParameters\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0mtraining_job\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mInputDataConfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOutputDataConfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhyperparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTrainingJobName\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0mLocalSagemakerClient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_training_jobs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTrainingJobName\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_job\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ec2-user/anaconda3/envs/mxnet_p27/lib/python2.7/site-packages/sagemaker/local/entities.pyc\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self, input_data_config, output_data_config, hyperparameters, job_name)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         self.model_artifacts = self.container.train(\n\u001b[0;32m---> 89\u001b[0;31m             \u001b[0minput_data_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_data_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhyperparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m         )\n\u001b[1;32m     91\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ec2-user/anaconda3/envs/mxnet_p27/lib/python2.7/site-packages/sagemaker/local/image.pyc\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_data_config, output_data_config, hyperparameters, job_name)\u001b[0m\n\u001b[1;32m    151\u001b[0m             \u001b[0;31m# which contains the exit code and append the command line to it.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Failed to run: %s, %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcompose_command\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0martifacts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve_artifacts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompose_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_data_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Failed to run: ['docker-compose', '-f', '/tmp/tmphrunTU/docker-compose.yaml', 'up', '--build', '--abort-on-container-exit'], Process exited with code: 1"
     ]
    }
   ],
   "source": [
    "m.fit(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Host\n",
    "\n",
    "After training, we use the MXNet estimator object to deploy an endpoint. Because we trained locally, we'll also deploy the endpoint locally.  The predictor object returned by `deploy` lets us call the endpoint and perform inference on our sample images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = m.deploy(initial_instance_count=1, instance_type='local_gpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate\n",
    "\n",
    "We'll use these CIFAR-10 sample images to test the service:\n",
    "\n",
    "<img style=\"display: inline; height: 32px; margin: 0.25em\" src=\"images/airplane1.png\" />\n",
    "<img style=\"display: inline; height: 32px; margin: 0.25em\" src=\"images/automobile1.png\" />\n",
    "<img style=\"display: inline; height: 32px; margin: 0.25em\" src=\"images/bird1.png\" />\n",
    "<img style=\"display: inline; height: 32px; margin: 0.25em\" src=\"images/cat1.png\" />\n",
    "<img style=\"display: inline; height: 32px; margin: 0.25em\" src=\"images/deer1.png\" />\n",
    "<img style=\"display: inline; height: 32px; margin: 0.25em\" src=\"images/dog1.png\" />\n",
    "<img style=\"display: inline; height: 32px; margin: 0.25em\" src=\"images/frog1.png\" />\n",
    "<img style=\"display: inline; height: 32px; margin: 0.25em\" src=\"images/horse1.png\" />\n",
    "<img style=\"display: inline; height: 32px; margin: 0.25em\" src=\"images/ship1.png\" />\n",
    "<img style=\"display: inline; height: 32px; margin: 0.25em\" src=\"images/truck1.png\" />\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the CIFAR-10 samples, and convert them into format we can use with the prediction endpoint\n",
    "from cifar10_utils import read_images\n",
    "\n",
    "filenames = ['images/airplane1.png',\n",
    "             'images/automobile1.png',\n",
    "             'images/bird1.png',\n",
    "             'images/cat1.png',\n",
    "             'images/deer1.png',\n",
    "             'images/dog1.png',\n",
    "             'images/frog1.png',\n",
    "             'images/horse1.png',\n",
    "             'images/ship1.png',\n",
    "             'images/truck1.png']\n",
    "\n",
    "image_data = read_images(filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The predictor runs inference on our input data and returns the predicted class label (as a float value, so we convert to int for display)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i, img in enumerate(image_data):\n",
    "    response = predictor.predict(img)\n",
    "    print('image {}: class: {}'.format(i, int(response)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Cleanup\n",
    "\n",
    "After you have finished with this example, remember to delete the prediction endpoint.  Only one local endpoint can be running at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.delete_endpoint()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_mxnet_p27",
   "language": "python",
   "name": "conda_mxnet_p27"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  },
  "notice": "Copyright 2017 Amazon.com, Inc. or its affiliates. All Rights Reserved.  Licensed under the Apache License, Version 2.0 (the \"License\"). You may not use this file except in compliance with the License. A copy of the License is located at http://aws.amazon.com/apache2.0/ or in the \"license\" file accompanying this file. This file is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
